{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QRN9UYlUHEkJ",
        "outputId": "d1435a5f-7ba5-4a8e-f529-d2f6ec2c4625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your original dataset on Google Drive\n",
        "original_data_path = '/content/drive/MyDrive/archive/census.csv'  # Update with your dataset path\n",
        "\n",
        "# Load the original dataset using Pandas\n",
        "df = pd.read_csv(original_data_path)\n",
        "\n",
        "# Remove rows with missing values\n",
        "df = df.replace('?', np.nan)\n",
        "df = df.dropna()\n",
        "\n",
        "# Specify the path to save the cleaned dataset\n",
        "cleaned_data_path = '/content/drive/MyDrive/archive/census_cleaned.csv'  # Update with the desired path\n",
        "\n",
        "# Save the cleaned dataset to a new CSV file\n",
        "df.to_csv(cleaned_data_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your cleaned dataset on Google Drive\n",
        "cleaned_data_path = '/content/drive/MyDrive/archive/census_cleaned.csv'  # Update with your cleaned dataset path\n",
        "\n",
        "# Load the cleaned dataset using Pandas\n",
        "df = pd.read_csv(cleaned_data_path)\n",
        "\n",
        "# Define the target column\n",
        "target_column = 'income'  # Replace with your target variable\n",
        "\n",
        "# Define the categorical columns\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = df.drop(columns=[target_column])\n",
        "Y = df[target_column]\n",
        "\n",
        "# One-Hot Encoding for both features and target variable\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "X_encoded = encoder.fit_transform(X[categorical_columns])\n",
        "Y_encoded = encoder.fit_transform(Y.values.reshape(-1, 1))\n",
        "\n",
        "# Number of bootstrap samples\n",
        "n_samples = 100  # You can adjust this value\n",
        "\n",
        "# Initialize a list to store the accuracy results\n",
        "linear_accuracy = []\n",
        "\n",
        "# Perform bootstrap resampling and model training\n",
        "for _ in range(n_samples):\n",
        "    # Resample the dataset with replacement\n",
        "    X_sample, Y_sample = resample(X_encoded, Y_encoded, replace=True)\n",
        "\n",
        "    # Split the resampled data into a training set (you can adjust the test_size)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, Y_sample, test_size=0.2)\n",
        "\n",
        "    # Linear Regression\n",
        "    linear_reg = LinearRegression()\n",
        "    linear_reg.fit(X_train, y_train)\n",
        "    linear_accuracy.append(linear_reg.score(X_test, y_test))\n",
        "\n",
        "# Calculate the mean accuracy for Linear Regression\n",
        "mean_accuracy_linear = np.mean(linear_accuracy)\n",
        "\n",
        "print(f'Linear Regression Accuracy: {mean_accuracy_linear}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSdkaLZNN5dC",
        "outputId": "c2d57a2b-e978-4ef3-c02f-a32f35ffb2ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Accuracy: -1.4109050897675327e+19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your cleaned dataset on Google Drive\n",
        "cleaned_data_path = '/content/drive/MyDrive/archive/census_cleaned.csv'  # Update with your cleaned dataset path\n",
        "\n",
        "# Load the cleaned dataset using Pandas\n",
        "df = pd.read_csv(cleaned_data_path)\n",
        "\n",
        "# Define the target column\n",
        "target_column = 'income'  # Replace with your target variable\n",
        "\n",
        "# Define the categorical columns\n",
        "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
        "\n",
        "# Separate the features and target variable\n",
        "X = df.drop(columns=[target_column])\n",
        "Y = df[target_column]\n",
        "\n",
        "# One-Hot Encoding for both features and target variable\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "X_encoded = encoder.fit_transform(X[categorical_columns])\n",
        "Y_encoded = encoder.fit_transform(Y.values.reshape(-1, 1))\n",
        "\n",
        "# Number of bootstrap samples\n",
        "n_samples = 100  # You can adjust this value\n",
        "\n",
        "# Initialize a list to store the accuracy results\n",
        "linear_accuracy = []\n",
        "\n",
        "# Perform bootstrap resampling and model training\n",
        "for _ in range(n_samples):\n",
        "    # Resample the dataset with replacement\n",
        "    X_sample, Y_sample = resample(X_encoded, Y_encoded, replace=True)\n",
        "\n",
        "    # Split the resampled data into a training set (you can adjust the test_size)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, Y_sample, test_size=0.2)\n",
        "\n",
        "    # Linear Regression\n",
        "    linear_reg = LinearRegression()\n",
        "    linear_reg.fit(X_train, y_train)\n",
        "    linear_accuracy.append(linear_reg.score(X_test, y_test))\n",
        "\n",
        "# Calculate the mean accuracy for Linear Regression\n",
        "mean_accuracy_linear = np.mean(linear_accuracy)\n",
        "\n",
        "print(f'Linear Regression Accuracy: {mean_accuracy_linear}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8w_iw9VO8z_",
        "outputId": "b5068943-f293-4404-bf78-40ab71d1c657"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression Accuracy: -4.041728437883906e+17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# Number of bootstrap samples\n",
        "n_samples = 100  # You can adjust this value\n",
        "\n",
        "# Initialize a list to store the accuracy results\n",
        "ridge_accuracy = []\n",
        "\n",
        "# Perform bootstrap resampling and model training for Ridge Regression\n",
        "for _ in range(n_samples):\n",
        "    # Resample the dataset with replacement\n",
        "    X_sample, Y_sample = resample(X_encoded, Y_encoded, replace=True)\n",
        "\n",
        "    # Split the resampled data into a training set (you can adjust the test_size)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, Y_sample, test_size=0.2)\n",
        "\n",
        "    # Ridge Regression\n",
        "    ridge_reg = Ridge(alpha=1.0)  # You can adjust the alpha parameter for regularization\n",
        "    ridge_reg.fit(X_train, y_train)\n",
        "    ridge_accuracy.append(ridge_reg.score(X_test, y_test))\n",
        "\n",
        "# Calculate the mean accuracy for Ridge Regression\n",
        "mean_accuracy_ridge = np.mean(ridge_accuracy)\n",
        "\n",
        "print(f'Ridge Regression Accuracy: {mean_accuracy_ridge}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qv3UlljQvVp",
        "outputId": "3c8cf9d7-0a44-48b4-e5b1-4f167fb54382"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge Regression Accuracy: 0.33343449046747686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Number of bootstrap samples (reduced for faster execution)\n",
        "n_samples = 5 # You can adjust this value\n",
        "\n",
        "# Initialize a list to store the accuracy results\n",
        "knn_accuracy = []\n",
        "\n",
        "# Perform bootstrap resampling and model training for KNN\n",
        "for _ in range(n_samples):\n",
        "    # Resample the dataset with replacement\n",
        "    X_sample, Y_sample = resample(X_encoded, Y_encoded, replace=True)\n",
        "\n",
        "    # Split the resampled data into a training set (you can adjust the test_size)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, Y_sample, test_size=0.2)\n",
        "\n",
        "    # k-Nearest Neighbors (KNN)\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    knn_accuracy.append(knn.score(X_test, y_test))\n",
        "\n",
        "# Calculate the mean accuracy for KNN\n",
        "mean_accuracy_knn = np.mean(knn_accuracy)\n",
        "\n",
        "print(f'k-Nearest Neighbors (KNN) Accuracy: {mean_accuracy_knn}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8kg-_FiRaoO",
        "outputId": "6e972e20-b634-46fd-8c95-087286d2fc75"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k-Nearest Neighbors (KNN) Accuracy: 0.8152791597567717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ydq1y5YRt-f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}